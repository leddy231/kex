{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0c44b72c526c8c2d5c61f5343e5a1f2700c1b4b253758e0d185049d36041666fd",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from wordEmbedders import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggestWordsForCluster(wordvectors, cluster):\n",
    "    cluster = set(cluster)\n",
    "    candidates = set([])\n",
    "    for word in cluster:\n",
    "        for w, distance in wordvectors.most_similar(word):\n",
    "            if w not in cluster:\n",
    "                candidates.add(w)\n",
    "    out = []\n",
    "    for c in candidates:\n",
    "        out.append((c, np.average(wordvectors.distances(c, cluster))))\n",
    "    out.sort(key=lambda x: x[1])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'IMDB'\n",
    "modelFile = f'./models/{dataset}/Word2Vec.model'\n",
    "wv = Word2Vec.load(modelFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('top_notch', 0.5095391)\n('superb', 0.51829046)\n('outstanding', 0.5419428)\n('pretty_good', 0.5439246)\n('amazing', 0.54664433)\n('fabulous', 0.55199707)\n('phenomenal', 0.55372417)\n('marvellous', 0.5545981)\n('incredible', 0.5736557)\n('first_rate', 0.5812179)\n('exceptional', 0.5874356)\n('marvelous', 0.5933228)\n('pretty_cool', 0.60975015)\n('magnificent', 0.6115242)\n('splendid', 0.6163283)\n('pretty_decent', 0.6173191)\n('decent', 0.62340504)\n('absolutely_amazing', 0.6287398)\n('nicely_done', 0.63331896)\n('alright', 0.6557807)\n('passable', 0.66536707)\n('below_average', 0.6697382)\n('uniformly_excellent', 0.67031443)\n('awful', 0.6732474)\n('interesting', 0.6802691)\n('bad', 0.6839771)\n('cute', 0.69487095)\n('neat', 0.69760376)\n('cheesy', 0.7182783)\n('funny', 0.7185991)\n('pleasant', 0.73870176)\n('hot', 0.77199167)\n('watchable', 0.7773117)\n"
     ]
    }
   ],
   "source": [
    "positiveWords = [\"good\",'nice','great','wonderful','terrific','cool','fantastic','excellent','awesome','brilliant']\n",
    "for word in suggestWordsForCluster(wv, positiveWords):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('appalling', 0.50595665)\n('god_awful', 0.52027214)\n('unbelievably_bad', 0.5300555)\n('extremely_poor', 0.5331172)\n('sub_par', 0.53416383)\n('absolutely_terrible', 0.5369204)\n('pathetic', 0.5388743)\n('truly_awful', 0.53970456)\n('absolutely_atrocious', 0.54830515)\n('laughably_bad', 0.54886687)\n('poorly_done', 0.5707064)\n('mediocre', 0.577185)\n('lame', 0.58730936)\n('amateurish', 0.58829844)\n('crappy', 0.597208)\n('good', 0.6034783)\n('cheesy', 0.6068131)\n('abominable', 0.61176044)\n('dismal', 0.61886305)\n('second_rate', 0.6357393)\n"
     ]
    }
   ],
   "source": [
    "negativeWords = [\"bad\",'awful','horrible','terrible','atrocious','horrid','horrendous','dreadful','abysmal','lousy']\n",
    "for word in suggestWordsForCluster(wv, negativeWords):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/{dataset}/positiveWords.txt', mode='w') as f:\n",
    "    f.write(','.join(positiveWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/{dataset}/negativeWords.txt', mode='w') as f:\n",
    "    f.write(','.join(negativeWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}