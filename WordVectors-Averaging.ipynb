{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0c44b72c526c8c2d5c61f5343e5a1f2700c1b4b253758e0d185049d36041666fd",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from wordEmbedders import Word2Vec, WESCScore, AverageClassifier, AverageTFIDFClassifier, MinMaxClassifier, MinMaxTFIDFClassifier\n",
    "from tqdm.notebook import tqdm\n",
    "from prettytable import PrettyTable, ALL\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['AirlineTweets']\n",
    "#datasets = ['Sentiment140']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordEmbedders = [Word2Vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [AverageClassifier, AverageTFIDFClassifier, MinMaxClassifier, MinMaxTFIDFClassifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveWords = [\"good\", \"nice\", \"cool\", \"lovely\", \"wonderful\", \"great\", \"awesome\", \"fantastic\", \"amazing\", \"fun\", \"excellent\"]\n",
    "negativeWords = [\"bad\", \"horrible\", \"terrible\", \"awful\", \"worst\", \"shitty\", \"crappy\", \"sucks\", \"hate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Datasets:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "361aec2620ea4c2aa1311df03b8ed8e0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/11541 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df286f54c57e47df91a341aa8d9f2191"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/11541 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c9de60fa5d94acdb69987b910b09348"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/11541 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c939dc9427e043a38258e9776ab97853"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/11541 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "377aeb24a3464a1596055a0670e231a4"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "out = []\n",
    "for dataset in tqdm(datasets, desc=\"Datasets\"):\n",
    "    dataFile   = f'./data/{dataset}/Data-Cleaned.csv'\n",
    "    tfidfFile  = f'./models/{dataset}/TF-IDF.model'\n",
    "    dictFile   = f'./models/{dataset}/Dictionary.model'\n",
    "    tfidf = TfidfModel.load(tfidfFile)\n",
    "    dct   = Dictionary.load(dictFile)\n",
    "    if not os.path.exists(dataFile):\n",
    "        raise ValueError(f'Dataset {dataset} has not been cleaned')\n",
    "    \n",
    "    df = pd.read_csv(dataFile)\n",
    "        \n",
    "    embedderOut = []\n",
    "    for embedder in wordEmbedders:\n",
    "        modelFile = f'./models/{dataset}/{embedder.name}.model'\n",
    "        if not os.path.exists(modelFile):\n",
    "            raise ValueError(f'Dataset {dataset} has no {embedder} trained')\n",
    "        model = embedder.load(modelFile)\n",
    "\n",
    "        for classifier in classifiers:\n",
    "            classifier = classifier(model, positiveWords, negativeWords, tfidf, dct)\n",
    "\n",
    "            columnPredict = f\"{embedder.name}_{classifier.name}_predict\"\n",
    "            columnPredictCorrect = f\"{embedder.name}_{classifier.name}_predict_correct\"\n",
    "\n",
    "            #predict results\n",
    "            result = classifier.predict(df)\n",
    "            embedderOut.append((embedder.name, classifier.name, result))\n",
    "\n",
    "    out.append((dataset, embedderOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Baseline dataset evaluation\n\nAirlineTweets:\n+------------+--------------+-------------------+----------+------------------+\n| Embeddings | Averaging    | Balanced Accuracy | F1 Score | Confusion Matrix |\n+------------+--------------+-------------------+----------+------------------+\n| Word2Vec   | Average      |           0.53841 |  0.16236 |       223 | 161  |\n|            |              |                   |          |      -----+----- |\n|            |              |                   |          |      2140 | 9017 |\n+------------+--------------+-------------------+----------+------------------+\n| Word2Vec   | AverageTFIDF |           0.48133 |  0.31813 |      1929 | 7835 |\n|            |              |                   |          |      -----+----- |\n|            |              |                   |          |       434 | 1343 |\n+------------+--------------+-------------------+----------+------------------+\n| Word2Vec   | MinMax       |           0.48115 |  0.32461 |      2121 | 8584 |\n|            |              |                   |          |      -----+----- |\n|            |              |                   |          |       242 | 594  |\n+------------+--------------+-------------------+----------+------------------+\n| Word2Vec   | MinMaxTFIDF  |           0.51166 |  0.04914 |        60 | 19   |\n|            |              |                   |          |      -----+----- |\n|            |              |                   |          |      2303 | 9159 |\n+------------+--------------+-------------------+----------+------------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline dataset evaluation\")\n",
    "for resultset in out:\n",
    "    (dataset, results) = resultset\n",
    "    table = PrettyTable(['Embeddings', 'Averaging', 'Balanced Accuracy', 'F1 Score', 'Confusion Matrix'])\n",
    "    table.align['Embeddings'] = 'l'\n",
    "    table.align['Averaging'] = 'l'\n",
    "    table.align['Balanced Accuracy'] = 'r'\n",
    "    table.align['F1 Score'] = 'r'\n",
    "    table.align['Confusion Matrix'] = 'r'\n",
    "    table.hrules = ALL\n",
    "    for result in results:\n",
    "        name, classifier, result = result\n",
    "        table.add_row([name, classifier, '%.5f' % result.balancedAccuracy, '%.5f' % result.f1Score, result.confusionMatrix])\n",
    "\n",
    "\n",
    "    print(f\"\\n{dataset}:\")\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}