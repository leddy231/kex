{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0c44b72c526c8c2d5c61f5343e5a1f2700c1b4b253758e0d185049d36041666fd",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import prettytable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook  import tqdm\n",
    "from functions      import readSet, dirs\n",
    "from gensim.models  import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "from prettytable    import PrettyTable\n",
    "from wordEmbedders  import Word2Vec, WESCScore, AverageClassifier\n",
    "#from gensim.models import Word2Vec\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dirs('./data')\n",
    "#datasets = ['AirlineTweets']\n",
    "#ignoreCache = True\n",
    "ignoreCache = False\n",
    "datasetSpecificClusters = True\n",
    "embedder = Word2Vec\n",
    "classifier = AverageClassifier\n",
    "positiveWords = readSet('./wordlists/positiveWords.txt')\n",
    "negativeWords = readSet('./wordlists/negativeWords.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Datasets:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "58ddead2e600404e8f411e0f9d2987dc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AirlineTweets2: using cached data\n",
      "IMDB: using cached data\n",
      "Sentiment140: using cached data\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "for dataset in tqdm(datasets, desc=\"Datasets\"):\n",
    "    dataFile   = f'./data/{dataset}/Data-Cleaned.csv'\n",
    "    outputFile = f'./data/{dataset}/{embedder.name}-Prediction.csv'\n",
    "    modelFile  = f'./models/{dataset}/{embedder.name}.model'\n",
    "    tfidfFile  = f'./models/{dataset}/TF-IDF.model'\n",
    "    dictFile   = f'./models/{dataset}/Dictionary.model'\n",
    "    tfidf = TfidfModel.load(tfidfFile)\n",
    "    dct   = Dictionary.load(dictFile)\n",
    "\n",
    "    if not os.path.exists(dataFile):\n",
    "        raise ValueError(f'Dataset {dataset} has not been cleaned')\n",
    "    if not os.path.exists(modelFile):\n",
    "        raise ValueError(f'Dataset {dataset} has no {embedder.name} trained')\n",
    "\n",
    "    if datasetSpecificClusters:\n",
    "        positiveWords = readSet(f'./data/{dataset}/positiveWords.txt')\n",
    "        negativeWords = readSet(f'./data/{dataset}/negativeWords.txt')\n",
    "    \n",
    "    if os.path.exists(outputFile) and not ignoreCache:\n",
    "        print(f'{dataset}: using cached data')\n",
    "        result = WESCScore.load(outputFile)\n",
    "    else:\n",
    "        print(f'{dataset}: predicting')\n",
    "        df     = pd.read_csv(dataFile)\n",
    "        model  = embedder.load(modelFile)\n",
    "        #model  = Word2Vec.load(modelFile).wv\n",
    "        clas   = classifier(model, positiveWords, negativeWords, tfidf, dct)\n",
    "        result = clas.predict(df)\n",
    "        result.save(outputFile)\n",
    "\n",
    "    out.append((dataset, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Baseline dataset evaluation\n+----------------+--------------------+------------------+\n|    Dataset     | Balanced Accuracy  | Confusion Matrix |\n+----------------+--------------------+------------------+\n| AirlineTweets2 | 0.6258187116462933 |   1165 | 3819    |\n|                |                    |   -----+-----    |\n|                |                    |    350 | 3563    |\n+----------------+--------------------+------------------+\n|      IMDB      |      0.62762       |   7206 | 825     |\n|                |                    |  ------+------   |\n|                |                    |  17794 | 24175   |\n+----------------+--------------------+------------------+\n|  Sentiment140  |    0.597770625     | 677373 | 520940  |\n|                |                    | -------+-------  |\n|                |                    | 122627 | 279060  |\n+----------------+--------------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline dataset evaluation\")\n",
    "table = PrettyTable(['Dataset', 'Balanced Accuracy', 'Confusion Matrix'])\n",
    "for dataset, result in out:\n",
    "    #acc = (result.truePos + result.trueNeg) / len(result.data)\n",
    "    table.add_row([dataset, result.balancedAccuracy, result.confusionMatrix])\n",
    "table.hrules = prettytable.ALL\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}