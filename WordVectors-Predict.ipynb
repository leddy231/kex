{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0c44b72c526c8c2d5c61f5343e5a1f2700c1b4b253758e0d185049d36041666fd",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import prettytable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook  import tqdm\n",
    "from functions      import readSet, dirs\n",
    "from gensim.models  import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "from prettytable    import PrettyTable\n",
    "from wordEmbedders  import Word2Vec, WESCScore, AverageClassifier\n",
    "#from gensim.models import Word2Vec\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dirs('./data')\n",
    "#datasets = ['AirlineTweets']\n",
    "ignoreCache = True\n",
    "embedder = Word2Vec\n",
    "classifier = AverageClassifier\n",
    "positiveWords = readSet('./wordlists/positiveWords.txt')\n",
    "negativeWords = readSet('./wordlists/negativeWords.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Datasets:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee4d05d7557d4c3399d8dde5f9845147"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AirlineTweets: predicting\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/11541 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb15cdb076504787a7ea128b1ed9d667"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "IMDB: predicting\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/50000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "737024b892514335993bae2e5e402639"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sentiment140: predicting\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/1600000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "687123a8fdb64615b9ec0931b41b88bc"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "out = []\n",
    "for dataset in tqdm(datasets, desc=\"Datasets\"):\n",
    "    dataFile   = f'./data/{dataset}/Data-Cleaned.csv'\n",
    "    outputFile = f'./data/{dataset}/{embedder.name}-Prediction.csv'\n",
    "    modelFile  = f'./models/{dataset}/{embedder.name}.model'\n",
    "    tfidfFile  = f'./models/{dataset}/TF-IDF.model'\n",
    "    dictFile   = f'./models/{dataset}/Dictionary.model'\n",
    "    tfidf = TfidfModel.load(tfidfFile)\n",
    "    dct   = Dictionary.load(dictFile)\n",
    "\n",
    "    if not os.path.exists(dataFile):\n",
    "        raise ValueError(f'Dataset {dataset} has not been cleaned')\n",
    "    if not os.path.exists(modelFile):\n",
    "        raise ValueError(f'Dataset {dataset} has no {embedder.name} trained')\n",
    "    \n",
    "    if os.path.exists(outputFile) and not ignoreCache:\n",
    "        print(f'{dataset}: using cached data')\n",
    "        result = WESCScore.load(outputFile)\n",
    "    else:\n",
    "        print(f'{dataset}: predicting')\n",
    "        df     = pd.read_csv(dataFile)\n",
    "        model  = embedder.load(modelFile)\n",
    "        #model  = Word2Vec.load(modelFile).wv\n",
    "        clas   = classifier(model, positiveWords, negativeWords, tfidf, dct)\n",
    "        result = clas.predict(df)\n",
    "        result.save(outputFile)\n",
    "\n",
    "    out.append((dataset, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Baseline dataset evaluation\n+---------------+--------------------+--------------------+---------------------+------------------+\n|    Dataset    |      Accuracy      | Balanced Accuracy  |          F1         | Confusion Matrix |\n+---------------+--------------------+--------------------+---------------------+------------------+\n| AirlineTweets | 0.8084221471276319 | 0.5453603609876125 | 0.17592247484159523 |    236 | 84      |\n|               |                    |                    |                     |   -----+-----    |\n|               |                    |                    |                     |   2127 | 9094    |\n+---------------+--------------------+--------------------+---------------------+------------------+\n|      IMDB     |       0.5755       |       0.5755       |  0.279409268375488  |   4115 | 340     |\n|               |                    |                    |                     |  ------+------   |\n|               |                    |                    |                     |  20885 | 24660   |\n+---------------+--------------------+--------------------+---------------------+------------------+\n|  Sentiment140 |     0.68300625     |     0.68300625     |  0.6744566682499133 | 525395 | 232585  |\n|               |                    |                    |                     | -------+-------  |\n|               |                    |                    |                     | 274605 | 567415  |\n+---------------+--------------------+--------------------+---------------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline dataset evaluation\")\n",
    "table = PrettyTable(['Dataset', 'Accuracy', 'Balanced Accuracy', 'F1', 'Confusion Matrix'])\n",
    "for dataset, result in out:\n",
    "    acc = (result.truePos + result.trueNeg) / len(result.data)\n",
    "    table.add_row([dataset, acc, result.balancedAccuracy, result.f1Score, result.confusionMatrix])\n",
    "table.hrules = prettytable.ALL\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-e0be91b24ebe>, line 1)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-e0be91b24ebe>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Single word for good and bad\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Single word for good and bad\n",
    "+---------------+--------------------+--------------------+--------------------+------------------+\n",
    "|    Dataset    |      Accuracy      | Balanced Accuracy  |         F1         | Confusion Matrix |\n",
    "+---------------+--------------------+--------------------+--------------------+------------------+\n",
    "| AirlineTweets | 0.5347023654795945 | 0.4920447449867007 | 0.2697851509382649 |    992 | 3999    |\n",
    "|               |                    |                    |                    |   -----+-----    |\n",
    "|               |                    |                    |                    |   1371 | 5179    |\n",
    "+---------------+--------------------+--------------------+--------------------+------------------+\n",
    "|      IMDB     |      0.57672       |      0.57672       | 0.7009720809313892 |  24806 | 20970   |\n",
    "|               |                    |                    |                    |  ------+------   |\n",
    "|               |                    |                    |                    |    194 | 4030    |\n",
    "+---------------+--------------------+--------------------+--------------------+------------------+\n",
    "|  Sentiment140 |    0.669751875     |    0.669751875     | 0.6459582799263771 | 482037 | 210434  |\n",
    "|               |                    |                    |                    | -------+-------  |\n",
    "|               |                    |                    |                    | 317963 | 589566  |\n",
    "+---------------+--------------------+--------------------+--------------------+------------------+"
   ]
  }
 ]
}