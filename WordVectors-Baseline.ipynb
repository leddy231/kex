{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0c44b72c526c8c2d5c61f5343e5a1f2700c1b4b253758e0d185049d36041666fd",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from wordEmbedders import Word2Vec, WESCScore, WESClassifier\n",
    "from tqdm.notebook import tqdm\n",
    "from prettytable import PrettyTable\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = os.listdir('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordEmbedders = [Word2Vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveWords = [\"good\", \"nice\", \"cool\", \"lovely\", \"wonderful\", \"great\", \"awesome\", \"fantastic\", \"amazing\", \"fun\", \"excellent\"]\n",
    "negativeWords = [\"bad\", \"horrible\", \"terrible\", \"awful\", \"worst\", \"shitty\", \"crappy\", \"sucks\", \"hate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Datasets:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df783cadf4a84f8faa85de175d5be1d8"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "out = []\n",
    "for dataset in tqdm(datasets, desc=\"Datasets\"):\n",
    "    dataFile   = f'./data/{dataset}/Data-Cleaned.csv'\n",
    "    outputFile = f'./data/{dataset}/Data-Predicted.csv'\n",
    "    if not os.path.exists(dataFile):\n",
    "        raise ValueError(f'Dataset {dataset} has not been cleaned')\n",
    "    \n",
    "    if os.path.exists(outputFile):\n",
    "        df = pd.read_csv(outputFile)\n",
    "    else:\n",
    "        df = pd.read_csv(dataFile)\n",
    "\n",
    "    embedderOut = []\n",
    "    for embedder in wordEmbedders:\n",
    "        columnPredict = f\"{embedder.name}_predict\"\n",
    "        columnPredictCorrect = f\"{embedder.name}_predict_correct\"\n",
    "\n",
    "        if columnPredict in df: \n",
    "            #load previus results\n",
    "            data = pd.DataFrame()\n",
    "            data['truth'] = df['sentiment']\n",
    "            data['predicted'] = df[columnPredict]\n",
    "            result = WESCScore(data)\n",
    "            embedderOut.append((embedder.name, result))\n",
    "        else:\n",
    "            #predict results\n",
    "            modelFile = f'./models/{dataset}/{embedder.name}.model'\n",
    "            if not os.path.exists(modelFile):\n",
    "                raise ValueError(f'Dataset {dataset} has no {embedder} trained')\n",
    "\n",
    "            model = embedder.load(modelFile)\n",
    "            classifier = WESClassifier(model, positiveWords, negativeWords)\n",
    "            result = classifier.predict(df)\n",
    "            embedderOut.append((embedder.name, result))\n",
    "            df[columnPredict] = result.data['predicted']\n",
    "            df[columnPredictCorrect] = result.correctPredictions\n",
    "\n",
    "    df.to_csv(outputFile, index=False)\n",
    "    out.append((dataset, embedderOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Baseline dataset evaluation\n\nAirlineTweets:\n+------------+--------------------+---------------------+\n| Embeddings |      Accuracy      |          F1         |\n+------------+--------------------+---------------------+\n|  Word2Vec  | 0.5384148067187106 | 0.16235893702220605 |\n+------------+--------------------+---------------------+\n\nIMDB:\n+------------+--------------------+--------------------+\n| Embeddings |      Accuracy      |         F1         |\n+------------+--------------------+--------------------+\n|  Word2Vec  | 0.5616399999999999 | 0.2339577799524675 |\n+------------+--------------------+--------------------+\n\nSentiment140:\n+------------+-----------+--------------------+\n| Embeddings |  Accuracy |         F1         |\n+------------+-----------+--------------------+\n|  Word2Vec  | 0.6862125 | 0.6727609289350358 |\n+------------+-----------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline dataset evaluation\")\n",
    "for resultset in out:\n",
    "    (dataset, results) = resultset\n",
    "    table = PrettyTable(['Embeddings', 'Accuracy', 'F1'])\n",
    "    for result in results:\n",
    "        name, result = result\n",
    "        table.add_row([name, result.balancedAccuracy, result.f1Score])\n",
    "\n",
    "    print(f\"\\n{dataset}:\")\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}